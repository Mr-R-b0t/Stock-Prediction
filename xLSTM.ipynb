{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voRkZ4xJK4vF"
      },
      "outputs": [],
      "source": [
        "!export CUDA_LIB=/usr/local/cuda/lib64\n",
        "!pip install omegaconf dacite xlstm yfinance ninja\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from google.colab import files\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from omegaconf import OmegaConf\n",
        "from dacite import from_dict, Config as DaciteConfig\n",
        "from xlstm import xLSTMLMModel, xLSTMLMModelConfig\n",
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available!\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Check your installation.\")"
      ],
      "metadata": {
        "id": "o3Bk_qviQat5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import xlstm.blocks.slstm.src.cuda_init as cuda_init\n",
        "import os\n",
        "\n",
        "# Clear the cache\n",
        "cache_dir = \"/root/.cache/torch_extensions\"\n",
        "if os.path.exists(cache_dir):\n",
        "    shutil.rmtree(cache_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "tMIIi_KCRWDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = \"AAPL\"  # Remplacez par le ticker de l'action souhaitée\n",
        "data = yf.download(ticker, period=\"max\")"
      ],
      "metadata": {
        "id": "cUNE0TmILJAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Préparation des données pour l'entraînement\n",
        "data = data[['Close']]  # Ne conserver que la colonne 'Close'\n",
        "data = data.reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "TsnF6bcSPK1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = scaler.fit_transform(data)\n"
      ],
      "metadata": {
        "id": "AX9tFVeXPMsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StockDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.from_numpy(self.X[idx]).float()\n",
        "        y = torch.from_numpy(self.y[idx]).float()\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "C3-G_j5xPZUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_back = 60  # Nombre de valeurs passées à l'LSTM\n",
        "X = []\n",
        "y = []\n",
        "for i in range(len(data) - look_back - 1):\n",
        "    X.append(data[i:i + look_back])\n",
        "    y.append(data[i + look_back])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "iTRleTPSPdTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StockDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.from_numpy(self.X[idx]).float()\n",
        "        y = torch.from_numpy(self.y[idx]).float()\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "sxtfjCZ1PqYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = StockDataset(X, y)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "Btdjhd0DPsUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xlstm_cfg = \"\"\"\n",
        "vocab_size: 128  # Adjust based on number of features\n",
        "mlstm_block:\n",
        "  mlstm:\n",
        "    conv1d_kernel_size: 4\n",
        "    qkv_proj_blocksize: 4\n",
        "    num_heads: 4\n",
        "slstm_block:\n",
        "  slstm:\n",
        "    backend: cuda  # Enable if using CUDA\n",
        "    num_heads: 4\n",
        "    conv1d_kernel_size: 4\n",
        "    bias_init: powerlaw_blockdependent\n",
        "  feedforward:\n",
        "    proj_factor: 1.3\n",
        "    act_fn: gelu\n",
        "context_length: 360  # Update context length to match input size\n",
        "num_blocks: 7\n",
        "embedding_dim: 128\n",
        "slstm_at: [1]\n",
        "\"\"\"\n",
        "cfg = OmegaConf.create(xlstm_cfg)\n",
        "cfg = from_dict(data_class=xLSTMLMModelConfig, data=OmegaConf.to_container(cfg), config=DaciteConfig(strict=True))\n"
      ],
      "metadata": {
        "id": "MBaqweSzPueV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = xLSTMLMModel(cfg)\n",
        "\n",
        "# Définition du critère de perte et de l'optimiseur\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "DQ1IMBL8PyOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):  # Adjust number of epochs\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, targets) in enumerate(train_loader):  # Use the DataLoader you created earlier\n",
        "        # Move inputs and targets to the same device as the model\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Make predictions\n",
        "        # The model expects a 2D input (batch_size, sequence_length)\n",
        "        inputs = inputs.view(inputs.size(0), -1).long()\n",
        "\n",
        "        # Move the model to the same device as the data\n",
        "        model = model.to(device) # Add this line\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Select the last output for each sequence in the batch and the correct number of output features\n",
        "        outputs = outputs[:, -1, :6]  # Select all 6 features of the last output\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Update gradients\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track loss\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 0:\n",
        "            print(f\"[{epoch + 1}, {i + 1:4d}] loss: {running_loss / 100:.4f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "# Save trained model\n",
        "torch.save(model.state_dict(), \"model.pt\")\n"
      ],
      "metadata": {
        "id": "nEYcaS4dSHKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from xlstm import xLSTMLMModel, xLSTMLMModelConfig\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = xLSTMLMModel.from_pretrained(\"model.pt\")  # Replace with your model path\n",
        "\n",
        "# Define test data function (modify as needed)\n",
        "def get_test_data(ticker, look_back):\n",
        "    data = yf.download(ticker, period=\"max\")  # Download latest data\n",
        "    data = data[['Close']]\n",
        "    data = data.dropna()\n",
        "    data = scaler.transform(data)  # Assuming you have a scaler object from training\n",
        "    X = data[-look_back:]\n",
        "    return np.array([X])\n",
        "\n",
        "# Define test function\n",
        "def test_model(model, test_data, target):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        inputs = torch.from_numpy(test_data).float().to(device)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "    predicted_price = scaler.inverse_transform(outputs.cpu().detach().numpy())[0][0]\n",
        "    print(f\"Predicted price for {target} closing: {predicted_price:.2f}\")\n",
        "\n",
        "# Example usage (replace with your desired ticker and look_back)\n",
        "ticker = \"AAPL\"\n",
        "look_back = 60\n",
        "test_data = get_test_data(ticker, look_back)\n",
        "target = \"tomorrow\"  # Adjust target date description\n",
        "\n",
        "test_model(model, test_data, target)"
      ],
      "metadata": {
        "id": "bkxShWTPXUwG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}